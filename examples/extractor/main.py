#!/usr/bin/env python3
"""
Content Extractor Example

Demonstrates the powerful new Crawl4AI-based content extraction capabilities
that solve the reliability issues with previous extraction methods.
"""

import asyncio
from vibex import VibeX

async def main():
    """Run a content extraction demonstration."""

    print("ğŸš€ Content Extractor Example")
    print("=" * 70)
    print("Task: Test Crawl4AI extraction from challenging websites")
    print("Demonstrating: Reliable extraction from JavaScript sites, Reddit, etc.")
    print("Key Features: Parallel processing, search integration, no API failures")
    print("-" * 70)

    # Simplified task focused on basic extraction testing
    extraction_prompt = """Test the Crawl4AI content extraction by:

1. Extract content from 2-3 web development articles about trends in 2025
2. Test extraction from one challenging site (like a tech blog)
3. Save the extracted content to files

Keep it simple and focused on demonstrating reliable extraction."""

    print(f"ğŸ¯ Extraction Test: Testing Crawl4AI capabilities...")
    print("-" * 70)

    # Start the extraction test with VibeX
    x = await VibeX.start(
        project_id="content_extractor_project",
        goal=extraction_prompt,
        config_path="config/team.yaml"
    )

    print(f"ğŸ“‹ Project ID: {x.project_id}")
    print(f"ğŸ“ Workspace: {x.workspace.get_path()}")
    print("-" * 70)

    # Execute the extraction test
    print("ğŸ¤– X: Starting Crawl4AI extraction tests...")
    while not x.is_complete():
        response = await x.step()
        print(f"ğŸ”§ Extraction Step:\n{response}\n")
        print("-" * 70)

    # Simple test scenarios
    test_scenarios = [
        "Extract content from one more web development article",
        "Test extraction from a tech news site"
    ]

    for scenario in test_scenarios:
        print(f"ğŸ§ª Test Scenario: {scenario}")
        response = await x.chat(scenario)

        print(f"ğŸ” Extraction Result:\n{response}\n")
        print("-" * 70)

    print("âœ… Extraction testing completed!")
    print(f"ğŸ“ Check workspace for extracted content: {x.workspace.get_path()}")

    # Show the power of the new system
    print("\nğŸš€ Crawl4AI Extraction System Features Demonstrated:")
    print("   âœ… Handles JavaScript-heavy sites (Reddit, GitHub, etc.)")
    print("   âœ… Bypasses bot detection mechanisms")
    print("   âœ… Parallel processing for multiple URLs")
    print("   âœ… Search and extraction in one operation")
    print("   âœ… No API keys needed - fully open source")
    print("   âœ… No rate limits or service outages")
    print("   âœ… Clean markdown output ready for AI processing")

    print("\nğŸ’¬ Continue testing with X:")
    print("   Example: x.chat('Extract from 5 Reddit threads about Python frameworks')")
    print("   Example: x.chat('Test extraction from Twitter threads about AI')")
    print("   Example: x.chat('Extract academic papers about machine learning')")

if __name__ == "__main__":
    asyncio.run(main())
