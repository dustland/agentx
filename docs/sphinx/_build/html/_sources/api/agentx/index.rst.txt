agentx
======

.. py:module:: agentx

.. autoapi-nested-parse::

   AgentX - Multi-Agent Conversation Framework

   A flexible framework for building AI agent teams with:
   - Autonomous agents with private LLM interactions
   - Centralized tool execution for security and monitoring
   - Built-in storage, memory, and search capabilities
   - Team coordination and task management



Submodules
----------

.. toctree::
   :maxdepth: 1

   /api/agentx/builtin_tools/index
   /api/agentx/cli/index
   /api/agentx/config/index
   /api/agentx/core/index
   /api/agentx/event/index
   /api/agentx/memory/index
   /api/agentx/observability/index
   /api/agentx/run/index
   /api/agentx/search/index
   /api/agentx/server/index
   /api/agentx/storage/index
   /api/agentx/tool/index
   /api/agentx/utils/index


Classes
-------

.. autoapisummary::

   agentx.Agent
   agentx.Orchestrator
   agentx.Task
   agentx.TaskExecutor
   agentx.Tool


Functions
---------

.. autoapisummary::

   agentx.execute_task
   agentx.get_logger
   agentx.set_log_level
   agentx.setup_clean_chat_logging
   agentx.start_task
   agentx.tool


Package Contents
----------------

.. py:class:: Agent(config: agentx.core.config.AgentConfig, tool_manager=None)

   Represents an autonomous agent that manages its own conversation flow.

   Key Principles:
   - Each agent is autonomous and manages its own conversation flow
   - Agents communicate with other agents through public interfaces only
   - The brain is private to the agent - no external access
   - Tool execution is handled by orchestrator for security and control

   This combines:
   - AgentConfig (configuration data)
   - Brain (private LLM interaction)
   - Conversation management (delegates tool execution to orchestrator)

   Initialize agent with configuration and optional tool manager.

   :param config: Agent configuration
   :param tool_manager: Optional tool manager (injected by TaskExecutor)


   .. py:method:: __repr__() -> str


   .. py:method:: __str__() -> str


   .. py:method:: add_tool(tool)

      Add a tool to the agent's capabilities.



   .. py:method:: build_system_prompt(context: Dict[str, Any] = None) -> str

      Build the system prompt for the agent, including dynamic context and tool definitions.



   .. py:method:: generate_response(messages: List[Dict[str, Any]], system_prompt: Optional[str] = None, orchestrator=None, max_tool_rounds: int = 10) -> str
      :async:


      Generate response with tool execution handled by orchestrator.

      This is a simpler, non-streaming version that returns the final response.

      :param messages: Conversation messages in LLM format
      :param system_prompt: Optional system prompt override
      :param orchestrator: Orchestrator instance for tool execution
      :param max_tool_rounds: Maximum tool execution rounds

      :returns: Final response string



   .. py:method:: get_capabilities() -> Dict[str, Any]

      Get agent capabilities summary.



   .. py:method:: get_tools_json() -> List[Dict[str, Any]]

      Get the JSON schemas for the tools available to this agent.



   .. py:method:: remove_tool(tool_name: str)

      Remove a tool from the agent's capabilities.



   .. py:method:: reset_state()

      Reset agent state.



   .. py:method:: stream_response(messages: List[Dict[str, Any]], system_prompt: Optional[str] = None, orchestrator=None, max_tool_rounds: int = 10) -> AsyncGenerator[str, None]
      :async:


      Stream response with tool execution handled by orchestrator.

      This matches Brain's interface but includes tool execution loop.

      :param messages: Conversation messages in LLM format
      :param system_prompt: Optional system prompt override
      :param orchestrator: Orchestrator instance for tool execution
      :param max_tool_rounds: Maximum tool execution rounds

      :Yields: Response chunks and tool execution status updates



   .. py:method:: update_config(**kwargs)

      Update agent configuration.



   .. py:attribute:: brain


   .. py:attribute:: config


   .. py:attribute:: description


   .. py:attribute:: max_iterations


   .. py:attribute:: memory_enabled


   .. py:attribute:: name


   .. py:attribute:: state


   .. py:attribute:: tool_manager
      :value: None



   .. py:attribute:: tools


.. py:class:: Orchestrator(team_config: agentx.core.config.TeamConfig, message_queue: agentx.core.message.MessageQueue, tool_manager: agentx.tool.manager.ToolManager, agents: Dict[str, agentx.core.agent.Agent])

   .. py:method:: run(task: agentx.core.task.Task) -> AsyncGenerator[agentx.core.message.Message, None]
      :async:



   .. py:attribute:: agents


   .. py:attribute:: message_queue


   .. py:attribute:: routing_brain
      :type:  Optional[agentx.core.brain.Brain]


   .. py:attribute:: team_config


   .. py:attribute:: tool_manager


.. py:class:: Task(task_id: str, config: agentx.core.config.TaskConfig, history: agentx.core.message.TaskHistory, message_queue: agentx.core.message.MessageQueue, agents: Dict[str, agentx.core.agent.Agent], workspace: agentx.storage.workspace.WorkspaceStorage, orchestrator: agentx.core.orchestrator.Orchestrator, initial_prompt: str)

   Represents the state and context of a single task being executed.
   This class is a data container and does not have execution logic.


   .. py:method:: complete()

      Marks the task as complete.



   .. py:method:: get_agent(name: str) -> agentx.core.agent.Agent

      Retrieves an agent by name.



   .. py:method:: get_context() -> Dict[str, Any]

      Returns a dictionary with the task's context.



   .. py:attribute:: agents


   .. py:attribute:: config


   .. py:attribute:: created_at
      :type:  datetime.datetime


   .. py:attribute:: history


   .. py:attribute:: initial_prompt


   .. py:attribute:: is_complete
      :type:  bool
      :value: False



   .. py:attribute:: message_queue


   .. py:attribute:: orchestrator


   .. py:attribute:: plan
      :type:  Optional[agentx.core.plan.Plan]


   .. py:attribute:: task_id


   .. py:attribute:: workspace


.. py:class:: TaskExecutor(team_config: Union[agentx.core.config.TeamConfig, str], task_id: Optional[str] = None, workspace_dir: Optional[pathlib.Path] = None)

   The main engine for executing a task. It coordinates the agents, tools,
   and orchestrator to fulfill the user's request.


   .. py:method:: start(prompt: str, stream: bool = False) -> AsyncGenerator[agentx.core.message.Message, None]
      :async:


      Starts the task execution and streams back events.



   .. py:attribute:: agents


   .. py:attribute:: history


   .. py:attribute:: message_queue


   .. py:attribute:: orchestrator


   .. py:attribute:: task
      :type:  Optional[Task]
      :value: None



   .. py:attribute:: task_id
      :value: ''



   .. py:attribute:: tool_manager


   .. py:attribute:: workspace


.. py:class:: Tool(name: str = '')

   Bases: :py:obj:`abc.ABC`


   Base class for tools that provide multiple callable methods for LLMs.


   .. py:method:: get_callable_methods() -> Dict[str, Callable]

      Get all methods marked with @tool decorator.



   .. py:method:: get_tool_schemas() -> Dict[str, Dict[str, Any]]

      Get detailed OpenAI function schemas for all callable methods using Pydantic.



   .. py:attribute:: name
      :value: ''



.. py:function:: execute_task(prompt: str, config_path: str, stream: bool = False) -> AsyncGenerator[agentx.core.message.Message, None]
   :async:


   High-level function to execute a task from a prompt and config file.
   This function runs the task to completion autonomously.


.. py:function:: get_logger(name: str, level: Optional[str] = None) -> logging.Logger

   Get a configured logger instance.

   Simple rule:
   - If streaming mode is active: AgentX loggers go to file only, others suppressed
   - If streaming mode is off: All loggers go to both console and file

   :param name: Logger name (usually __name__)
   :param level: Optional log level override

   :returns: Configured logger instance


.. py:function:: set_log_level(level: str)

   Set log level for the entire application.


.. py:function:: setup_clean_chat_logging()

   Configure logging for clean chat experience.


.. py:function:: start_task(prompt: str, config_path: str, task_id: Optional[str] = None, workspace_dir: Optional[pathlib.Path] = None) -> TaskExecutor

   High-level function to start a task and return the TaskExecutor for step-by-step execution.

   This function is ideal for interactive scenarios where you want to:
   - Execute tasks step by step
   - Inspect task state between steps
   - Modify task configuration during execution
   - Build interactive UIs with manual control

   :param prompt: The initial task prompt
   :param config_path: Path to the team configuration file
   :param task_id: Optional custom task ID
   :param workspace_dir: Optional custom workspace directory

   :returns: The initialized executor ready for step-by-step execution
   :rtype: TaskExecutor

   .. rubric:: Example

   ```python
   # Start a task for step-by-step execution
   executor = start_task(
       prompt="Write a research report",
       config_path="config/team.yaml"
   )

   # Execute steps manually
   async for message in executor.start(prompt, stream=True):
       print(f"Agent: {message.agent_name}")
       print(f"Content: {message.content}")

       # You can inspect state, pause, or modify between steps
       if some_condition:
           break
   ```


.. py:function:: tool(description: str = '', return_description: str = '')

   Decorator to mark a method as a callable tool for an LLM.


