# guardrails

Guardrails Engine - Comprehensive Safety and Compliance System

This module implements multi-layered safety mechanisms including input validation, output filtering, rate limiting, content safety, and policy compliance checks.

```python
from agentx.core.guardrails import ...
```

## Classes

### GuardrailContext

```python
class GuardrailContext
```

Context information for guardrail checks.


### RateLimitState

```python
class RateLimitState
```

Rate limiting state tracking.


### GuardrailRule

```python
class GuardrailRule(ABC)
```

Abstract base class for guardrail rules.

#### Methods

##### __init__

```python
def __init__(self, name, severity, action)
```


##### check

```python
def check(self, content, context)
```

Check content against this rule.



### InputValidationRule

```python
class InputValidationRule(GuardrailRule)
```

Input validation rule for sanitizing user inputs.

#### Methods

##### __init__

```python
def __init__(self, name, patterns, **kwargs)
```


##### check

```python
def check(self, content, context)
```

Check input against validation patterns.



### ContentFilterRule

```python
class ContentFilterRule(GuardrailRule)
```

Content filtering rule for blocking inappropriate content.

#### Methods

##### __init__

```python
def __init__(self, name, keywords, **kwargs)
```


##### check

```python
def check(self, content, context)
```

Check content for inappropriate keywords.



### RateLimitRule

```python
class RateLimitRule(GuardrailRule)
```

Rate limiting rule for preventing abuse.

#### Methods

##### __init__

```python
def __init__(self, name, max_requests, window_seconds, **kwargs)
```


##### check

```python
def check(self, content, context)
```

Check rate limits for the agent.



### ContentSafetyRule

```python
class ContentSafetyRule(GuardrailRule)
```

Content safety rule using pattern matching and heuristics.

#### Methods

##### __init__

```python
def __init__(self, name, safety_patterns, **kwargs)
```


##### check

```python
def check(self, content, context)
```

Check content for safety violations.



### ComplianceRule

```python
class ComplianceRule(GuardrailRule)
```

Compliance rule for organizational and regulatory requirements.

#### Methods

##### __init__

```python
def __init__(self, name, compliance_checks, **kwargs)
```


##### check

```python
def check(self, content, context)
```

Check content for compliance violations.



### GuardrailEngine

```python
class GuardrailEngine
```

Comprehensive guardrails engine for safety and compliance.

Implements multi-layered safety mechanisms including input validation, output filtering, rate limiting, content safety, and policy compliance.

#### Methods

##### __init__

```python
def __init__(self)
```


##### add_policy

```python
def add_policy(self, policy)
```

Add a guardrail policy to the engine.


##### check_content

```python
def check_content(self, content, context, policy_names)
```

Check content against guardrail policies.


##### should_block_content

```python
def should_block_content(self, guardrail_part)
```

Determine if content should be blocked based on guardrail results.


##### get_policy_names

```python
def get_policy_names(self)
```

Get list of available policy names.


##### get_policy_stats

```python
def get_policy_stats(self)
```

Get statistics about guardrail policies and checks.



## Functions

### get_guardrail_engine

```python
def get_guardrail_engine()
```

Get the global guardrail engine instance.


### check_content_safety

```python
def check_content_safety(content, agent_name, policy_names, task_id, step_id)
```

Convenience function to check content safety.

**Arguments:**

- `content`: Content to check
- `agent_name`: Name of the agent
- `policy_names`: Specific policies to check
- `task_id`: Optional task ID
- `step_id`: Optional step ID

**Returns:**

GuardrailPart with check results


### check

```python
def check(self, content, context)
```

Check content against this rule.


### check

```python
def check(self, content, context)
```

Check input against validation patterns.


### check

```python
def check(self, content, context)
```

Check content for inappropriate keywords.


### check

```python
def check(self, content, context)
```

Check rate limits for the agent.


### check

```python
def check(self, content, context)
```

Check content for safety violations.


### check

```python
def check(self, content, context)
```

Check content for compliance violations.


### add_policy

```python
def add_policy(self, policy)
```

Add a guardrail policy to the engine.


### check_content

```python
def check_content(self, content, context, policy_names)
```

Check content against guardrail policies.

**Arguments:**

- `content`: Content to check
- `context`: Context information
- `policy_names`: Specific policies to check (None for all applicable)

**Returns:**

GuardrailPart with check results


### should_block_content

```python
def should_block_content(self, guardrail_part)
```

Determine if content should be blocked based on guardrail results.


### get_policy_names

```python
def get_policy_names(self)
```

Get list of available policy names.


### get_policy_stats

```python
def get_policy_stats(self)
```

Get statistics about guardrail policies and checks.

