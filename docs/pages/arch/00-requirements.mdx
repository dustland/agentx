# AgentX Framework: Core Requirements

- [x] 1.  **File-Based Configuration:** The entire multi-agent team structure and collaboration workflow are defined in and loaded from static, file-based configurations (e.g., `team.yaml`). These configurations serve as the complete, declarative definition of a team.

- [x] 2.  **Orchestrator as Central Controller:** The `Orchestrator` is the primary entry point and central controller for a task. It is responsible for managing the _flow_ of the collaboration, not its content. Its duties include accepting the initial prompt, determining the next agent to act, dispatching tool calls, and terminating the collaboration based on defined conditions.

- [x] 3.  **Team State Management:** The framework maintains a persistent, file-based state for each task execution. This includes the conversation history, current agent, round count, artifacts, and other execution metadata stored in the task workspace.

- [x] 4.  **Agent Prompt Templates:** Each agent's behavior is defined by a Jinja2 template file that specifies its role, instructions, and context. The framework renders these templates with dynamic context (history, available tools, task prompt) to generate the agent's system prompt.

- [x] 5.  **Comprehensive Data Structures:** The framework uses well-defined Pydantic models for all data structures including TaskStep, ToolCall, ToolResult, Artifact, and various event types. These provide type safety, validation, and serialization.

- [x] 6.  **Event-Driven Architecture:** The framework emits structured events for all significant execution milestones (task start/complete, agent turns, tool calls, handoffs, errors) enabling monitoring, debugging, and integration with external systems.

- [x] 7.  **Message Streaming Support:** Separate from execution events, the framework supports real-time message streaming for UI updates, allowing clients to receive incremental content as it's generated by agents.

- [x] 8.  **Workspace Management:** Each task execution gets its own workspace directory containing state files, artifacts, history logs, and other task-specific data. This enables task persistence, resumption, and artifact management.

- [x] 9.  **Tool Integration:** The framework supports multiple tool types (builtin, python functions, MCP tools, HITL tools) with a unified interface. Tools are configured declaratively and can be shared across agents or restricted to specific agents.

- [x] 10. **LLM Provider Abstraction:** The framework abstracts LLM interactions through a unified interface supporting multiple providers (OpenAI, Anthropic, DeepSeek, Ollama, custom) with provider-specific optimizations and fallback mechanisms.

- [x] 11. **Handoff Rules:** Agent-to-agent handoffs are governed by explicit rules defined in the team configuration. These rules specify conditions, target agents, and handoff types (sequential, parallel) enabling sophisticated collaboration patterns.

- [x] 12. **Memory Management:** The framework provides both short-term (conversation context) and long-term (persistent) memory with semantic search capabilities. Memory operations are tracked and can be queried for debugging and optimization.

- [x] 13. **Guardrails and Safety:** Comprehensive safety mechanisms including input validation, output filtering, rate limiting, and content safety checks. Guardrail policies are configurable per agent and can block, warn, or log violations.

- [x] 14. **Human-in-the-Loop (HITL):** Built-in support for human intervention points through step-through execution mode, allowing users to pause execution, inspect state, modify context, and provide input at any point in the workflow.

- [x] 15. **Step-Through Debugging:** The framework supports step-by-step execution with breakpoints, allowing developers to pause execution, inspect state, modify context, and resume. Essential for development and debugging complex workflows.

- [ ] 16. **Production Deployment:** The framework includes deployment configurations, health checks, performance monitoring, and scaling capabilities for production environments including containerization and cloud deployment support.

- [x] 17. **Favor DeepSeek Models:** The framework defaults to DeepSeek models for reasoning and general scenarios, with easy configuration for other providers when needed.

- [x] 18. **Autonomous Task Execution:** The framework can execute tasks autonomously from start to completion, making intelligent decisions about agent handoffs, tool usage, and task termination without human intervention.

- [ ] 19. **Advanced Workspace Management:** Sophisticated workspace system with semantic search, automatic consolidation, and intelligent context management to maintain relevant information across long conversations.

- [x] 20. **Rich Artifact Management:** Advanced artifact handling including versioning, metadata tracking, cross-references, and support for various media types (code, documents, images, data).

- [ ] 21. **Intelligent Context Management:** Smart context compilation strategies, automatic summarization, and relevance-based filtering to optimize LLM context usage and maintain conversation coherence.
